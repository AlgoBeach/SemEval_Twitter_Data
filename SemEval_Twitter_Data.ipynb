{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SEMEVAL 2016\n",
    "\n",
    "## Data Download\n",
    "\n",
    "Download all the data for SEMEVAL competition\n",
    "\n",
    "Data details at: http://alt.qcri.org/semeval2016/task4/index.php?id=data-and-tools\n",
    "\n",
    "Download the file http://alt.qcri.org/semeval2016/task4/data/uploads/semeval2016-task4.traindevdevtest.v1.2.zip\n",
    "\n",
    "```\n",
    "wget http://alt.qcri.org/semeval2016/task4/data/uploads/semeval2016-task4.traindevdevtest.v1.2.zip\n",
    "cd data\n",
    "unzip semeval2016-task4.traindevdevtest.v1.2.zip\n",
    "```\n",
    "\n",
    "Extract all the tweet ids from all the files:\n",
    "```\n",
    "find ./data/ -name \"*.txt\" | grep -v README | xargs cut -f1 | sort | uniq > tweet_ids.txt\n",
    "```\n",
    "\n",
    "\n",
    "Install `tweepy` using `pip install tweepy`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import tweepy as tpy\n",
    "import pprint as pp\n",
    "import time\n",
    "import datetime\n",
    "import traceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load the authentication codes from the file\n",
    "authentication_file = \"auth_keys.json\"\n",
    "authentication_codes = json.load(open(authentication_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting already existing authentication codes.\n",
      "Initializing tweepy API\n"
     ]
    }
   ],
   "source": [
    "key_missing = lambda k,d: (k not in d) or d[k] == \"\"\n",
    "access_keys = [\"access_token\", \"access_token_secret\"]\n",
    "consumer_keys = [\"consumer_key\", \"consumer_secret\"]\n",
    "\n",
    "assert sum(key_missing(k, authentication_codes) for k in access_keys) == 0,\"Please set consumer key and consumer secret in %s\" % authentication_file\n",
    "auth = tpy.OAuthHandler(authentication_codes[consumer_keys[0]], authentication_codes[consumer_keys[1]])\n",
    "if sum(key_missing(k, authentication_codes) for k in access_keys):\n",
    "    # Start oauth dance and get the verification URL:\n",
    "    try:\n",
    "        redirect_url = auth.get_authorization_url()\n",
    "    except tpy.TweepError:\n",
    "        print 'Error! Failed to get request token.'\n",
    "    print \"Go to the following URL: \\n\", redirect_url\n",
    "    verifier = raw_input(\"Enter the verification code: \")\n",
    "    try:\n",
    "        auth.get_access_token(verifier)\n",
    "        authentication_codes[access_keys[0]] = auth.access_token\n",
    "        authentication_codes[access_keys[1]] = auth.access_token_secret\n",
    "        print \"Got new access token details. Saving to file: %s\" % authentication_file\n",
    "        json.dump(authentication_codes, open(authentication_file, \"wb+\"), indent=4)\n",
    "    except tpy.TweepError:\n",
    "        print 'Error! Failed to get access token.'\n",
    "else:\n",
    "    print \"Setting already existing authentication codes.\"\n",
    "    auth.set_access_token(authentication_codes[access_keys[0]], authentication_codes[access_keys[1]])\n",
    "\n",
    "print \"Initializing tweepy API\"\n",
    "api = tpy.API(auth)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "TWEETS_TEXT_FILE = \"TWEET_TEXT.txt\"\n",
    "TWEETS_DATA_FILE = \"TWEET_DATA.json\"\n",
    "TWEETS_IDS_FILE = \"tweet_ids.txt\"\n",
    "\n",
    "try:\n",
    "    tweets_data = json.load(open(TWEETS_DATA_FILE))\n",
    "    # Save backup of old data:\n",
    "    print \"Saving backup data in %s\" % (TWEETS_DATA_FILE+\".backup\")\n",
    "    json.dump(tweets_data, open(TWEETS_DATA_FILE+\".backup\", \"wb+\"))\n",
    "except:\n",
    "    print \"Either file %s doesn't exist or error reading file. Will create new file.\" % TWEETS_DATA_FILE\n",
    "    tweets_data = {}\n",
    "\n",
    "total, existing, new_downloaded, not_available = 0, 0, 0, 0\n",
    "text = \"\"\n",
    "with open(TWEETS_IDS_FILE) as tid_fp, open(TWEETS_TEXT_FILE, \"wb+\") as ttxt_fp:\n",
    "    for i, tid in enumerate(tid_fp.readlines()):\n",
    "        if (i % 50) == 0:\n",
    "            print \"Finished reading %s lines. Next TID: %s\" % (i, tid)\n",
    "        tid = tid[:-1]\n",
    "        if tid in tweets_data:\n",
    "            text = tweets_data[tid][\"text\"].replace(\"\\n\", \" \").replace(\"\\r\", \" \")\n",
    "            existing += 1\n",
    "            total += 1\n",
    "        while tid not in tweets_data:\n",
    "            try:\n",
    "                print \"Trying to download: %s, %s\" % (i, tid)\n",
    "                status = api.get_status(tid)\n",
    "                print \"Download success\"\n",
    "                tweets_data[tid] = status._json\n",
    "                text = status.text.replace(\"\\n\", \" \").replace(\"\\r\", \" \")\n",
    "                new_downloaded += 1\n",
    "                total += 1\n",
    "            except tpy.RateLimitError:\n",
    "                rate = api.rate_limit_status()\n",
    "                reset = rate['resources']['statuses']['/statuses/show/:id']['reset']\n",
    "                now = datetime.datetime.today()\n",
    "                future = datetime.datetime.fromtimestamp(reset)\n",
    "                seconds = (future-now).seconds+1\n",
    "                if seconds < 10000:\n",
    "                    print \"Rate limit exceeded, sleeping for %s seconds until %s\\n Will resume downloading: %s\" % (seconds, future, tid)\n",
    "                    print \"Finished downloading %s tweets. Total: %s, Existing: %s, Not Available: %s\" % (new_downloaded, total, existing, not_available)\n",
    "                    print \"Writing intermediate data with %s tweets to file: %s\" % (len(tweets_data), TWEETS_DATA_FILE+\".middle\")\n",
    "                    with open(TWEETS_DATA_FILE+\".middle\", \"wb+\") as fp_temp:\n",
    "                        json.dump(tweets_data, fp_temp)\n",
    "                    print \"Finished writing. Now sleeping for %s seconds.\" % seconds\n",
    "                    time.sleep(seconds)\n",
    "                    print \"Resume downloading: %s at %s\" % (tid, datetime.datetime.today())\n",
    "            except tpy.TweepError as e:\n",
    "                print \"Encountered error: \", e\n",
    "                if e.api_code in [34, 179, 144, 63]:\n",
    "                    print \"Tweet id: %s not found. Using placeholder text\" % tid\n",
    "                    text = \"Not Available\"\n",
    "                    tweets_data[tid] = {\"text\": text}\n",
    "                    not_available += 1\n",
    "                    total += 1\n",
    "                else:\n",
    "                    print \"Encountered some other error. Follow stack trace:\\n\", traceback.format_exc()\n",
    "                    raise\n",
    "            except:\n",
    "                print \"Encountered some other error. Follow stack trace:\\n\", traceback.format_exc()\n",
    "                raise\n",
    "        print \"Writng to %s to text file %s.\" % (tid, TWEETS_TEXT_FILE)\n",
    "        print >> ttxt_fp, \"%s\\t%s\" % (tid, text)\n",
    "        if new_downloaded % 100 == 0 and new_downloaded > 1:\n",
    "            print \"Finished downloading %s tweets. Total: %s, Existing: %s, Not Available: %s\" % (new_downloaded, total, existing, not_available)\n",
    "\n",
    "print \"Finished downloading all tweets. New: %s, Total: %s, Existing: %s, Not Available: %s\" % (new_downloaded, total, existing, not_available)\n",
    "print \"Writing new data with %s tweets to file: %s\" % (len(tweets_data), TWEETS_DATA_FILE)\n",
    "json.dump(tweets_data, open(TWEETS_DATA_FILE, \"wb+\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "629034528141647872\tLast day to see Jurassic World tomorrow and I kinda wanna see it I mean it is Ty's birthday so it makes sense to go again\r\n",
      "629035692450906112\tI get way too hype about October fuck February Halloween is my Valentine's Day\r\n",
      "629037053343305728\tFlying to Paris tomorrow morning! First on the agenda is have a croissant and some frog's legs with Zlatan on the Eiffel tower.\r\n",
      "629037957538672641\t@BestBuy - What time does the Apple Watch go on sale this Friday?\r\n",
      "629038344349970432\tBobby Jindal Misses Cut for 1st Prime-Time Presidential Debate: Indian-American presidential hopeful Bobby Jindal could not make it t...\r\n",
      "629048170333405184\t@noshoesnation 11th KC show, 6 different states! Would love to get my No Shoes Nation flag signed for my 20th birthday! See you at MetLife!\r\n",
      "629048875156959232\tOkay going to bed now, hope i can sleep this time ! Goodnight xx i'll see what happened at Metlife tomorrow!! Have fun y'all!! X\r\n",
      "629050880332050432\tNot Available\r\n",
      "629051270528172032\ti wish you was at MetLife:( https://t.co/pmy4uNecTI\r\n",
      "6290521651"
     ]
    }
   ],
   "source": [
    "! tail TWEET_TEXT.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
